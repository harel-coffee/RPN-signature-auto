{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the predictions of the single- and multi-center RPN signatures\n",
    "- This jupyter notebook is available on-line at:\n",
    "  - https://github.com/spisakt/RPN-signature/blob/master/notebooks/3_compare_predictions.ipynb\n",
    "- Input data for the notebook and non-standard code (PAINTeR library) is available in the repo:\n",
    "  - https://github.com/spisakt/RPN-signature\n",
    "- Raw MRI-data from study-centers 1 and 2 are available on OpenNeuro:\n",
    "  - https://openneuro.org/datasets/ds002608/versions/1.0.1\n",
    "  - https://openneuro.org/datasets/ds002609/versions/1.0.3\n",
    "- Raw data from center 3 is available upon reasonable request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T15:05:59.605064Z",
     "start_time": "2021-07-01T15:05:59.187036Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.209300Z",
     "start_time": "2021-07-14T17:54:36.162959Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'statsmodels.tsa.statespace._kalman_smoother.array' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-89c9bfbc8bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPAINTeR\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;31m# in-house lib used for the RPN-signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/src/RPN-signature/PAINTeR/plot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGLSAR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_ls\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantReg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_linear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMixedLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/regression/recursive_ls.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from statsmodels.tsa.statespace.mlemodel import (\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mMLEModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLEResults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLEResultsWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPredictionResults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     PredictionResultsWrapper)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimulation_smoother\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimulationSmoother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkalman_smoother\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmootherResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkalman_filter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINVERT_UNIVARIATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOLVE_LU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/simulation_smoother.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkalman_smoother\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKalmanSmoother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/kalman_smoother.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatespace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptionWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m from statsmodels.tsa.statespace.kalman_filter import (KalmanFilter,\n\u001b[1;32m     13\u001b[0m                                                       FilterResults)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/representation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from .tools import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfind_best_blas_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_matrix_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_vector_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_best_blas_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from . import (_initialization, _representation, _kalman_filter,\n\u001b[0m\u001b[1;32m     17\u001b[0m                _kalman_smoother, _simulation_smoother, _tools)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/statespace/_kalman_smoother.cpython-37m-darwin.so\u001b[0m in \u001b[0;36minit statsmodels.tsa.statespace._kalman_smoother\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'statsmodels.tsa.statespace._kalman_smoother.array' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.connectome import vec_to_sym_matrix, sym_matrix_to_vec\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "from mlxtend.evaluate import permutation_test\n",
    "from scipy.stats import f_oneway\n",
    "from scipy import stats\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from PAINTeR import plot # in-house lib used for the RPN-signature\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and merge behavioral data for all three centers (after exclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.214648Z",
     "start_time": "2021-07-14T17:54:36.162Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bochum = pd.read_csv(\"../res/bochum_sample_excl.csv\")\n",
    "df_essen = pd.read_csv(\"../res/essen_sample_excl.csv\")\n",
    "df_szeged = pd.read_csv(\"../res/szeged_sample_excl.csv\")\n",
    "df_bochum['study']='bochum'\n",
    "df_essen['study']='essen'\n",
    "df_szeged['study']='szeged'\n",
    "df=pd.concat((df_bochum, df_essen, df_szeged), sort=False)\n",
    "df=df.reset_index()\n",
    "y = df.mean_QST_pain_sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions for the original single-center and the newly proposed multi-center model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.216194Z",
     "start_time": "2021-07-14T17:54:36.163Z"
    }
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "multicener_predictions = np.genfromtxt('../res/multi-center/nested_cv_combat_conservative_pred_full_GroupKFold30.csv', delimiter=',')\n",
    "rpn_predictions = np.hstack((df_bochum.nested_prediction,\n",
    "                            df_essen.prediction,\n",
    "                            df_szeged.prediction))\n",
    "\n",
    "predictions = {\n",
    "    'single-center' : rpn_predictions,\n",
    "    'multi-center' : multicener_predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create study masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.217574Z",
     "start_time": "2021-07-14T17:54:36.165Z"
    }
   },
   "outputs": [],
   "source": [
    "study_masks = {\n",
    "    \"study 1\" : (df.study == 'bochum').values,\n",
    "    \"study 2\" : (df.study == 'essen').values,\n",
    "    \"study 3\" : (df.study == 'szeged').values,\n",
    "    \"study 1+2+3\" : np.array([True] * len(y))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed vs. Predicted plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.218787Z",
     "start_time": "2021-07-14T17:54:36.168Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(10,6), sharex=True, sharey=True)\n",
    "\n",
    "cols = ['tab:blue', 'tab:orange']\n",
    "\n",
    "for row, cv in enumerate(predictions.keys()):\n",
    "    for col, study in enumerate(study_masks.keys()):\n",
    "        g=sns.regplot(y[study_masks[study]], predictions[cv][study_masks[study]], ax=axs[row, col],\n",
    "                    scatter=True, scatter_kws={'alpha':0.3}, color=cols[row])\n",
    "        g.set(xlabel=None) \n",
    "        axs[row, col].set_xlim([-2, 2])\n",
    "        axs[row, col].set_ylim([-1.2, 1.2])\n",
    "        axs[row, col].spines['top'].set_visible(False)\n",
    "        axs[row, col].spines['bottom'].set_visible(False)\n",
    "        axs[row, col].spines['right'].set_visible(False)\n",
    "        axs[row, col].spines['left'].set_visible(False)\n",
    "        axs[row, col].grid(True)\n",
    "        \n",
    "        print('***', cv, study, '****************************************************')\n",
    "                   \n",
    "        corr = np.corrcoef(y[study_masks[study]], predictions[cv][study_masks[study]])[0,1]\n",
    "        axs[row, col].title.set_text(\"R={:.2f}\".format(corr))\n",
    "        print(\"R={:.2f}\".format(corr))\n",
    "        \n",
    "        # takes some seconds\n",
    "        p_corr = permutation_test(y[study_masks[study]], predictions[cv][study_masks[study]],\n",
    "                           func=lambda x, y: np.corrcoef(x, y)[0,1],\n",
    "                           method='approximate',\n",
    "                           num_rounds=8000,\n",
    "                           seed=42)\n",
    "        print(\"p_corr={:.5f}\".format(p_corr))\n",
    "        \n",
    "        mse = mean_squared_error(y[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"MSE={:.2f}\".format(mse))\n",
    "        \n",
    "        mae = mean_absolute_error(y[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"MSE={:.2f}\".format(mae))\n",
    "        \n",
    "        expvar = explained_variance_score(y[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"Expl. Var. ={:.3f}\".format(expvar))\n",
    "   \n",
    "   \n",
    "        \n",
    "plt.savefig('../res/multi-center/regplots_obs-pred_combat.pdf')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T12:15:17.151316Z",
     "start_time": "2021-07-04T12:15:17.148638Z"
    }
   },
   "source": [
    "## Violoin plots per center for the observed and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.220062Z",
     "start_time": "2021-07-14T17:54:36.170Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=df, x='study', y=predictions['single-center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.221254Z",
     "start_time": "2021-07-14T17:54:36.172Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=df, x='study', y=predictions['multi-center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.222509Z",
     "start_time": "2021-07-14T17:54:36.174Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=df, x='study', y='mean_QST_pain_sensitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.223966Z",
     "start_time": "2021-07-14T17:54:36.188Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.mean_QST_pain_sensitivity[df.study=='bochum'].mean())\n",
    "print(df.mean_QST_pain_sensitivity[df.study=='essen'].mean())\n",
    "print(df.mean_QST_pain_sensitivity[df.study=='szeged'].mean())\n",
    "\n",
    "f_oneway(df.mean_QST_pain_sensitivity[df.study=='bochum'],\n",
    "        df.mean_QST_pain_sensitivity[df.study=='essen'],\n",
    "        df.mean_QST_pain_sensitivity[df.study=='szeged'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove main site effect from observed pain sensitivity and re-calculate measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.226070Z",
     "start_time": "2021-07-14T17:54:36.190Z"
    }
   },
   "outputs": [],
   "source": [
    "y_res = np.copy(y.values)\n",
    "y_res[df.study=='bochum'] -= np.mean(y_res[df.study=='bochum'])\n",
    "y_res[df.study=='essen'] -= np.mean(y_res[df.study=='essen'])\n",
    "y_res[df.study=='szeged'] -= np.mean(y_res[df.study=='szeged'])\n",
    "\n",
    "df['mean_QST_pain_sensitivity_residual'] = y_res\n",
    "sns.violinplot(data=df, x='study', y='mean_QST_pain_sensitivity_residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.227968Z",
     "start_time": "2021-07-14T17:54:36.192Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(10,6), sharex=True, sharey=True)\n",
    "\n",
    "cols = ['tab:blue', 'tab:orange']\n",
    "\n",
    "for row, cv in enumerate(predictions.keys()):\n",
    "    for col, study in enumerate(study_masks.keys()):\n",
    "        g=sns.regplot(y_res[study_masks[study]], predictions[cv][study_masks[study]], ax=axs[row, col],\n",
    "                    scatter=True, scatter_kws={'alpha':0.3}, color=cols[row])\n",
    "        g.set(xlabel=None) \n",
    "        axs[row, col].set_xlim([-2, 2])\n",
    "        axs[row, col].set_ylim([-1.2, 1.2])\n",
    "        axs[row, col].spines['top'].set_visible(False)\n",
    "        axs[row, col].spines['bottom'].set_visible(False)\n",
    "        axs[row, col].spines['right'].set_visible(False)\n",
    "        axs[row, col].spines['left'].set_visible(False)\n",
    "        axs[row, col].grid(True)\n",
    "        \n",
    "        print('***', cv, study, '****************************************************')\n",
    "                   \n",
    "        corr = np.corrcoef(y_res[study_masks[study]], predictions[cv][study_masks[study]])[0,1]\n",
    "        axs[row, col].title.set_text(\"R={:.2f}\".format(corr))\n",
    "        print(\"R={:.2f}\".format(corr))\n",
    "        \n",
    "        # takes some seconds\n",
    "        p_corr = permutation_test(y_res[study_masks[study]], predictions[cv][study_masks[study]],\n",
    "                           func=lambda x, y: np.corrcoef(x, y)[0,1],\n",
    "                           method='approximate',\n",
    "                           num_rounds=8000,\n",
    "                           seed=42)\n",
    "        print(\"p_corr={:.5f}\".format(p_corr))\n",
    "        \n",
    "        mse = mean_squared_error(y_res[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"MSE={:.2f}\".format(mse))\n",
    "        \n",
    "        mae = mean_absolute_error(y_res[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"MSE={:.2f}\".format(mae))\n",
    "        \n",
    "        expvar = explained_variance_score(y_res[study_masks[study]], predictions[cv][study_masks[study]])\n",
    "        print(\"Expl. Var. ={:.3f}\".format(expvar))\n",
    "   \n",
    "   \n",
    "        \n",
    "plt.savefig('../res/multi-center/regplots_obs_resid-pred.pdf')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected correlation with study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.229864Z",
     "start_time": "2021-07-14T17:54:36.194Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import importlib\n",
    "import contextlib\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"\n",
    "    Context manager to patch joblib to report into tqdm progress bar given as argument\n",
    "    Based on: https://stackoverflow.com/questions/37804279/how-can-we-use-tqdm-in-a-parallel-execution-with-joblib\n",
    "    \"\"\"\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "\n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "#r_obs_pred = np.corrcoef(df.mean_QST_pain_sensitivity, predictions['multi-center'])[0,1]\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'observed': df.mean_QST_pain_sensitivity.values,\n",
    "        'predicted': predictions['multi-center'],\n",
    "        'confounder': df.study.astype(\"category\").cat.codes.values\n",
    "    })\n",
    "\n",
    "fit=ols(\"observed ~ predicted\", data=data).fit()\n",
    "print(\"R^2_(observed ~ predicted) =\", fit.rsquared)\n",
    "\n",
    "fit=ols(\"observed ~ C(confounder)\", data=data).fit()\n",
    "print(\"R^2_(observed ~ C(confounder)) =\", fit.rsquared)\n",
    "r2_obs_conf_true = fit.rsquared\n",
    "\n",
    "fit=ols(\"predicted ~ C(confounder)\", data=data).fit()\n",
    "print(\"R^2_(predicted ~ C(confounder) =\", fit.rsquared)\n",
    "r2_pred_conf_true = fit.rsquared\n",
    "\n",
    "\n",
    "corrs=[]\n",
    "nulldata=[]\n",
    "\n",
    "tolerance = 0.05\n",
    "\n",
    "\n",
    "\n",
    "def workhorse(i):\n",
    "    rng = np.random.default_rng(42+i)\n",
    "    data_rs = pd.DataFrame(\n",
    "        {\n",
    "        'observed': df.mean_QST_pain_sensitivity.values,\n",
    "        'predicted': predictions['multi-center'],\n",
    "        'confounder': rng.permutation(df.study.astype(\"category\").cat.codes.values)\n",
    "        })\n",
    "    r2_obs_conf_rs = ols(\"observed ~ C(confounder)\", data=data_rs).fit().rsquared\n",
    "    \n",
    "    if (np.abs(r2_obs_conf_rs - r2_obs_conf_true) < tolerance):\n",
    "        #print(\"Resampled R^2_(observed ~ C(confounder)) =\", r2_obs_conf_rs)\n",
    "        fit=ols(\"predicted ~ C(confounder)\", data=data_rs).fit()\n",
    "        #print(\"Resampled  R^2_(predicted ~ C(confounder) =\", fit.rsquared)     \n",
    "        return fit.rsquared, r2_obs_conf_rs\n",
    "    return np.nan, np.nan\n",
    "    \n",
    "num_perms=100000  \n",
    "with tqdm_joblib(tqdm(desc='permuting', total=num_perms)) as progress_bar:\n",
    "            res = Parallel(n_jobs=-1)(delayed(workhorse)(i) for i in np.arange(num_perms))\n",
    "    \n",
    "\n",
    "nulldata, corrs = zip(*res)\n",
    "nulldata = np.array(nulldata)\n",
    "nulldata = nulldata[~np.isnan(nulldata)]\n",
    "print(len(nulldata))\n",
    "sns.distplot(nulldata)\n",
    "plt.axvline(r2_pred_conf_true)\n",
    "\n",
    "print(\"p=\", np.sum(nulldata>=r2_pred_conf_true)/len(nulldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.231607Z",
     "start_time": "2021-07-14T17:54:36.195Z"
    }
   },
   "outputs": [],
   "source": [
    "corrs = np.array(corrs)\n",
    "sns.distplot(corrs[~np.isnan(corrs)])\n",
    "plt.axvline(r2_pred_conf_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.233069Z",
     "start_time": "2021-07-14T17:54:36.197Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import importlib\n",
    "import contextlib\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"\n",
    "    Context manager to patch joblib to report into tqdm progress bar given as argument\n",
    "    Based on: https://stackoverflow.com/questions/37804279/how-can-we-use-tqdm-in-a-parallel-execution-with-joblib\n",
    "    \"\"\"\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "\n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "#r_obs_pred = np.corrcoef(df.mean_QST_pain_sensitivity, predictions['multi-center'])[0,1]\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'observed': df.mean_QST_pain_sensitivity.values,\n",
    "        'predicted': predictions['multi-center'],\n",
    "        'confounder': df.study.astype(\"category\").cat.codes.values\n",
    "    })\n",
    "\n",
    "fit=ols(\"observed ~ predicted\", data=data).fit()\n",
    "print(\"R^2_(observed ~ predicted) =\", fit.rsquared)\n",
    "\n",
    "fit=ols(\"observed ~ C(confounder)\", data=data).fit()\n",
    "print(\"R^2_(observed ~ C(confounder)) =\", fit.rsquared)\n",
    "r2_obs_conf_true = fit.rsquared\n",
    "\n",
    "fit=ols(\"predicted ~ C(confounder)\", data=data).fit()\n",
    "print(\"R^2_(predicted ~ C(confounder) =\", fit.rsquared)\n",
    "r2_pred_conf_true = fit.rsquared\n",
    "\n",
    "\n",
    "    corrs=[]\n",
    "    nulldata=[]\n",
    "\n",
    "    tolerance = 0.001\n",
    "\n",
    "\n",
    "\n",
    "    def workhorse(i):\n",
    "        rng = np.random.default_rng(4242+i)\n",
    "        data_rs = pd.DataFrame(\n",
    "            {\n",
    "            'observed': df.mean_QST_pain_sensitivity.values,\n",
    "            'predicted': predictions['multi-center'],\n",
    "            'confounder': rng.permutation(df.study.astype(\"category\").cat.codes.values)\n",
    "            })\n",
    "        r2_obs_conf_rs = ols(\"observed ~ C(confounder)\", data=data_rs).fit().rsquared\n",
    "\n",
    "        if (np.abs(r2_obs_conf_rs - r2_obs_conf_true) < tolerance):\n",
    "            #print(\"Resampled R^2_(observed ~ C(confounder)) =\", r2_obs_conf_rs)\n",
    "            fit=ols(\"predicted ~ C(confounder)\", data=data_rs).fit()\n",
    "            #print(\"Resampled  R^2_(predicted ~ C(confounder) =\", fit.rsquared)     \n",
    "            return fit.rsquared, r2_obs_conf_rs\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    num_perms=1000000 \n",
    "    with tqdm_joblib(tqdm(desc='permuting', total=num_perms)) as progress_bar:\n",
    "                res = Parallel(n_jobs=-1)(delayed(workhorse)(i) for i in np.arange(num_perms))\n",
    "\n",
    "\n",
    "    nulldata, corrs = zip(*res)\n",
    "    nulldata = np.array(nulldata)\n",
    "    nulldata = nulldata[~np.isnan(nulldata)]\n",
    "    print(len(nulldata))\n",
    "    sns.distplot(nulldata)\n",
    "    plt.axvline(r2_pred_conf_true)\n",
    "\n",
    "    print(\"p=\", np.sum(nulldata>=r2_pred_conf_true)/len(nulldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.235165Z",
     "start_time": "2021-07-14T17:54:36.199Z"
    }
   },
   "outputs": [],
   "source": [
    "corrs = np.array(corrs)\n",
    "sns.distplot(corrs[~np.isnan(corrs)])\n",
    "plt.axvline(r2_obs_conf_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.237504Z",
     "start_time": "2021-07-14T17:54:36.201Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "print((np.max(nulldata)-np.min(nulldata))/10)\n",
    "\n",
    "g=sns.distplot(nulldata, norm_hist=True, bins=10)\n",
    "plt.axvline(r2_pred_conf_true, c='red')\n",
    "g.set(xlabel=None) \n",
    "g.spines['top'].set_visible(False)\n",
    "g.spines['bottom'].set_visible(False)\n",
    "g.spines['right'].set_visible(False)\n",
    "g.spines['left'].set_visible(False)\n",
    "g.grid(True)\n",
    "plt.savefig('../res/multi-center/hist_center_bias.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.239156Z",
     "start_time": "2021-07-14T17:54:36.203Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "def binom_interval(success, total, confint=0.95):\n",
    "    quantile = (1 - confint) / 2.\n",
    "    lower = beta.ppf(quantile, success, total - success + 1)\n",
    "    upper = beta.ppf(1 - quantile, success + 1, total - success)\n",
    "    return (lower, upper)\n",
    "\n",
    "binom_interval(256*0.6484375, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted vs. Predicted plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.240378Z",
     "start_time": "2021-07-14T17:54:36.204Z"
    }
   },
   "outputs": [],
   "source": [
    "g=sns.jointplot(predictions['single-center'], predictions['multi-center'], kind='reg', color='black', scatter = False )\n",
    "g.ax_joint.scatter(predictions['single-center'],predictions['multi-center'], c=df.mean_QST_pain_sensitivity,\n",
    "                   cmap=\"coolwarm\")\n",
    "g.fig.set_size_inches(6,6)\n",
    "g.ax_joint.set(xlabel=None) \n",
    "g.ax_joint.set_xlim([-2, 2])\n",
    "g.ax_joint.set_ylim([-1.2, 1.2])\n",
    "g.ax_joint.spines['top'].set_visible(False)\n",
    "g.ax_joint.spines['bottom'].set_visible(False)\n",
    "g.ax_joint.spines['right'].set_visible(False)\n",
    "g.ax_joint.spines['left'].set_visible(False)\n",
    "g.ax_joint.grid(True)\n",
    "plt.savefig('../res/multi-center/regplots_pred-pred_combat.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.241785Z",
     "start_time": "2021-07-14T17:54:36.206Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = plt.Normalize(df.mean_QST_pain_sensitivity.min(), df.mean_QST_pain_sensitivity.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "plt.colorbar(sm)\n",
    "plt.savefig('../res/multi-center/regplots_pred-pred_colorbar.pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:54:36.242993Z",
     "start_time": "2021-07-14T17:54:36.208Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef(predictions['single-center'], predictions['multi-center'])[0,1]\n",
    "print(\"R={:.2f}\".format(corr))\n",
    "        \n",
    "# takes some seconds\n",
    "p_corr = permutation_test(y[study_masks[study]], predictions[cv][study_masks[study]],\n",
    "                           func=lambda x, y: np.corrcoef(x, y)[0,1],\n",
    "                           method='approximate',\n",
    "                           num_rounds=8000,\n",
    "                           seed=42)\n",
    "print(\"p_corr={:.5f}\".format(p_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
